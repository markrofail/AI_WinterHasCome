{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### general_search\n",
    "The general search is exactly the code in the lecture slides. The only modification is the expanded nodes count and filtering visited nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/general_search.png\" alt=\"drawing\" width=\"450\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_search(problem, queueing_function):\n",
    "    nodes = [Node(problem.initial_state)]\n",
    "    visited = list()         # modification: filter visited nodes\n",
    "    count = 0                # modicication: return number of expanded nodes\n",
    "    while nodes:\n",
    "        node = nodes.pop(0)  # remove front\n",
    "        visited.append(node)\n",
    "        if problem.goal_test(node.state):\n",
    "            return node, count\n",
    "        nodes = queueing_function(nodes, node.expand(problem))\n",
    "        nodes = filter_visited(nodes, visited)\n",
    "        count += 1\n",
    "    return None, count\n",
    "\n",
    "def filter_visited(nodes, visited):\n",
    "    return list(set(nodes) - set(visited))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### breadth first search\n",
    "\n",
    "uses the general_search but utlisies the `enqueue_at_end` queueing strategy which appends the expanded nodes to the back of the node queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##########################\n",
    "# Breadth First Search (BFS)\n",
    "# ##########################\n",
    "\n",
    "\n",
    "def breadth_first_search(problem):\n",
    "    return general_search(problem, enqueue_at_end)\n",
    "\n",
    "\n",
    "def enqueue_at_end(nodes, expanded_nodes):\n",
    "    nodes.extend(expanded_nodes)\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### depth first search\n",
    "\n",
    "uses the general_search but utlisies the `enqueue_at_front` queueing strategy which appends the expanded nodes to the front of the node queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################\n",
    "# Depth First Search (DFS)\n",
    "# ########################\n",
    "\n",
    "\n",
    "def depth_first_search(problem):\n",
    "    return general_search(problem, enqueue_at_front)\n",
    "\n",
    "\n",
    "def enqueue_at_front(nodes, expanded_nodes):\n",
    "    expanded_nodes.extend(nodes)\n",
    "    return expanded_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iterative_deepening_search\n",
    "\n",
    "uses the general_search in a loop but utlisies the `enqueue_at_front_cutoff` queueing strategy which appends the expanded nodes to the front of the node queue if their depth is less than the cut off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################\n",
    "# Iterative Deepening (ID)\n",
    "# ########################\n",
    "\n",
    "\n",
    "def iterative_deepening_search(problem):\n",
    "    total_count = 0\n",
    "    for i in itertools.count():\n",
    "        solution, count = depth_limited_search(problem, i)\n",
    "        total_count += total_count\n",
    "        if solution:\n",
    "            return solution, total_count\n",
    "\n",
    "\n",
    "def depth_limited_search(problem, depth):\n",
    "    cutoff_queue_func = functools.partial(enqueue_at_front_cutoff, depth)\n",
    "    return general_search(problem, cutoff_queue_func)\n",
    "\n",
    "\n",
    "def enqueue_at_front_cutoff(depth, nodes, expanded_nodes):\n",
    "    nodes = enqueue_at_front(nodes, expanded_nodes)\n",
    "    return [x for x in nodes if x.depth <= depth]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### uniform_cost_search\n",
    "\n",
    "uses the general_search but utlisies the `ordered_insert` queueing strategy which appends the expanded nodes to the node queue then sorts it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################\n",
    "# Uniform Cost Search (UC)\n",
    "# ########################\n",
    "\n",
    "\n",
    "def uniform_cost_search(problem):\n",
    "    return general_search(problem, ordered_insert)\n",
    "\n",
    "\n",
    "def ordered_insert(nodes, expanded_nodes):\n",
    "    nodes.extend(expanded_nodes)\n",
    "    ordered_nodes = sorted(nodes, key=operator.attrgetter('path_cost'))\n",
    "    return ordered_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### greedy_search\n",
    "\n",
    "uses the general_search but utlisies the `ordered_eval_insert` queueing strategy which appends the expanded nodes to the node queue then sorts it according to the `eval_function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################\n",
    "# Greedy Search (GC)\n",
    "# ##################\n",
    "\n",
    "\n",
    "def greedy_search_1(problem):\n",
    "    return best_first_search(problem, heuristic_1)\n",
    "\n",
    "\n",
    "def greedy_search_2(problem):\n",
    "    return best_first_search(problem, heuristic_2)\n",
    "\n",
    "\n",
    "def greedy_search_3(problem):\n",
    "    return best_first_search(problem, heuristic_3)\n",
    "\n",
    "\n",
    "def best_first_search(problem, eval_function):\n",
    "    heuristic_queue_func = functools.partial(ordered_eval_insert, eval_function)\n",
    "    return general_search(problem, heuristic_queue_func)\n",
    "\n",
    "\n",
    "def ordered_eval_insert(eval_function, nodes, expanded_nodes):\n",
    "    nodes.extend(expanded_nodes)\n",
    "    heuristic_nodes = [(node, eval_function(node)) for node in nodes]\n",
    "    ordered_nodes = sorted(heuristic_nodes, key=lambda x: x[1])\n",
    "    return [x for x, y in ordered_nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### heuristic definitions\n",
    "\n",
    "1. **first heuristic:**\n",
    "returns the distance to the closest white walker/dragon stone\n",
    "\n",
    "2. **second heuristic:**\n",
    "returns the sum of all distances to the white walkers\n",
    "\n",
    "3. **third heuristic:**\n",
    "returns the number of white walkers remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_1(node):\n",
    "    \"\"\"returns smallest distance between white walkers or dragon stone and current position\"\"\"\n",
    "    x_node, y_node = node.state.location()\n",
    "    goals = node.state.grid.components.white_walkers\n",
    "    goals.append(node.state.grid.components.dragon_stone)\n",
    "    distance = [np.sqrt((x_node - x)**2 + (y_node - y)**2) for x, y in goals]\n",
    "    return distance[np.argmin(distance)]\n",
    "\n",
    "\n",
    "def heuristic_2(node):\n",
    "    \"\"\"returns sum of distances between white walkers and current position\"\"\"\n",
    "    x_node, y_node = node.state.location()\n",
    "    goals = node.state.grid.components.white_walkers\n",
    "    distance = [np.sqrt((x_node - x)**2 + (y_node - y)**2) for x, y in goals]\n",
    "    return np.sum(distance)\n",
    "\n",
    "\n",
    "def heuristic_3(node):\n",
    "    \"\"\"number of white_walkers\"\"\"\n",
    "    return node.state.white_walkers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a_star\n",
    "\n",
    "uses the general_search but utlisies the `ordered_eval_insert` queueing strategy which appends the expanded nodes to the node queue then sorts it according to the `eval_function` + `path_cost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################\n",
    "# A Star Search (AC)\n",
    "# ##################\n",
    "\n",
    "\n",
    "def a_star_1(problem):\n",
    "    return best_first_search(problem, a_heuristic_1)\n",
    "\n",
    "\n",
    "def a_star_2(problem):\n",
    "    return best_first_search(problem, a_heuristic_2)\n",
    "\n",
    "\n",
    "def a_star_3(problem):\n",
    "    return best_first_search(problem, a_heuristic_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_heuristic_1(node):\n",
    "    return node.path_cost + heuristic_1(node)\n",
    "\n",
    "\n",
    "def a_heuristic_2(node):\n",
    "    return node.path_cost + heuristic_2(node)\n",
    "\n",
    "\n",
    "def a_heuristic_3(node):\n",
    "    return node.path_cost + heuristic_3(node)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
